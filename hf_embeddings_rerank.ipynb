{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2851cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def consine_sim(matrix_a, matrix_b):\n",
    "    dot_product = np.dot(matrix_a, matrix_b)\n",
    "    norm_a = np.linalg.norm(matrix_a)\n",
    "    norm_b = np.linalg.norm(matrix_b)\n",
    "    if not norm_a or not norm_b:\n",
    "        return 0\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045dec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6z/_mbtzcbj1jqgz31dn78zr_rr0000gn/T/ipykernel_76908/2502226545.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf_embedding = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf_embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d788e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_compare(model: HuggingFaceEmbeddings, left_word: str, right_word: str):\n",
    "    results = model.embed_documents([left_word, right_word])\n",
    "    consine = consine_sim(results[0], results[1])\n",
    "    print(f\"Similarity between [{left_word}] and [{right_word}] = [{consine}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af8154d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between [dog] and [หมา] = [0.8699827953438755]\n"
     ]
    }
   ],
   "source": [
    "hf_compare(hf_embedding, \"dog\", \"หมา\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be7e22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between [What the dog saw?] and [the dog is on the brige, looking at the river] = [0.7056555478007607]\n"
     ]
    }
   ],
   "source": [
    "hf_compare(hf_embedding, \"What the dog saw?\", \"the dog is on the brige, looking at the river\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6904d09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between [What the dog saw?] and [the cat is on the brige, looking at the river] = [0.58584010338901]\n"
     ]
    }
   ],
   "source": [
    "hf_compare(hf_embedding, \"What the dog saw?\", \"the cat is on the brige, looking at the river\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a94e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "reranker_model_name = 'BAAI/bge-reranker-v2-m3'\n",
    "tokenizer = AutoTokenizer.from_pretrained(reranker_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(reranker_model_name)\n",
    "model.eval()\n",
    "\n",
    "def hf_rerank_compare(left_word: str, right_word: str):\n",
    "    with torch.no_grad():\n",
    "        input = tokenizer([[left_word, right_word]],\n",
    "                          padding=True,\n",
    "                          truncation=True,\n",
    "                          return_tensors='pt',\n",
    "                          max_length=8194)\n",
    "        scores = model(**input, return_dict=True).logits.view(-1, ).float()\n",
    "        print(f\"ReRank similarity between [{left_word}] and [{right_word}] = {scores.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ec677c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [dog] and [หมา] = 4.895456314086914\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare(\"dog\", \"หมา\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfb7c4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [What the dog saw?] and [the dog is on the brige, looking at the river] = -2.162883996963501\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare(\"What the dog saw?\", \"the dog is on the brige, looking at the river\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88e8dce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [What the dog saw?] and [the dog is on the brige, it was looking at the river] = -0.7420030832290649\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare(\"What the dog saw?\", \"the dog is on the brige, it was looking at the river\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dda1d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [What the dog saw?] and [the cat is on the brige, looking at the river] = -9.531991958618164\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare(\"What the dog saw?\", \"the cat is on the brige, looking at the river\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c17d8347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [What the dog saw?] and [the dog was surrounded by 4 sides of wall] = -3.717414140701294\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare(\"What the dog saw?\", \"the dog was surrounded by 4 sides of wall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab55591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [what is panda?] and [The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.] = 5.265038967132568\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare('what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "362395de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [what is panda?] and [Panda is an animal] = 5.520259857177734\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare('what is panda?', 'Panda is an animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7207d97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [what is panda?] and [PANDA is an ANIMAL] = 5.4594407081604\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare('what is panda?', 'PANDA is an ANIMAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce117fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [คุณพูดภาษาไทยไหม?] and [ฉันไม่พูดภาษาไทย] = -1.1652841567993164\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare(\"คุณพูดภาษาไทยไหม?\", \"ฉันไม่พูดภาษาไทย\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "947cc5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [คุณพูดภาษาไทยไหม?] and [I can not speak Thai] = -1.0544286966323853\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare(\"คุณพูดภาษาไทยไหม?\", \"I can not speak Thai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a13527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [คุณพูดภาษาไทยไหม?] and [ฉันพูดภาษาไทย] = 2.0975513458251953\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare(\"คุณพูดภาษาไทยไหม?\", \"ฉันพูดภาษาไทย\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50db6c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReRank similarity between [สมบัติพูดภาษาไทยไหม?] and [สมบัติสามารถพูดได้ 3 ภาษา คือ ไทย อังกฤษ และ ญี่ปุ่น] = 5.681005477905273\n"
     ]
    }
   ],
   "source": [
    "hf_rerank_compare(\"สมบัติพูดภาษาไทยไหม?\", \"สมบัติสามารถพูดได้ 3 ภาษา คือ ไทย อังกฤษ และ ญี่ปุ่น\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
